{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $D = \\{(x_i, y_i)\\}_{i=1}^N$ be a training dataset. The goal is to train a linear classifier in a form of $y(x) = sign(x^Tw + b)$\n",
    "\n",
    "## SVM with soft-margins\n",
    "__Primal problem__\n",
    "\n",
    "$$ \\min_{\\xi_i, w, b} \\sum_{i=1}^N \\xi_i + C\\|w\\|_2^2$$\n",
    "$$\\text{s.t.} ~~~~ y_i (x_i^Tw + b) \\geq 1 - \\xi_i$$\n",
    "$$ \\xi_i \\geq 0 $$\n",
    "\n",
    "Lets rewrite the conditions on $\\xi_i$:\n",
    "$$\n",
    "\\begin{cases}\n",
    "\\xi_i \\geq& 1 - y_i (x_i^Tw + b) \\\\\n",
    "\\xi_i \\geq& 0\n",
    "\\end{cases}\n",
    "$$\n",
    "taking into account this conditions and the fact that in the objective we want to minimize $\\xi_i$ we may conclude that:\n",
    "\n",
    "$$\\xi_i = \\max(0, 1 - y_i (x_i^Tw + b))$$\n",
    "\n",
    "And the optimization problem can be formulated as follows:\n",
    "\n",
    "$$ \\min_{\\xi_i, w, b} \\sum_{i=1}^N \\max(0, 1 - y_i (x_i^Tw + b)) + C\\|w\\|_2^2$$\n",
    "\n",
    "\n",
    "\n",
    "## Logistic Regression\n",
    "\n",
    "In logistic regression we model the $p(y=+1|x)$ via linear function and sigmoid:\n",
    "$$ p(y=+1|x) = y(x) = \\sigma(x^Tw + b) = \\dfrac{1}{1 + e^{-(x^Tw + b)}} $$\n",
    "\n",
    "To find the parameters $w, b$ we follow maximum-likelihood approach, and the optimization problem is the following:\n",
    "\n",
    "$$ \\max_{w, b} \\sum_{i=1}^N [y_i = +1]\\log(\\sigma(x^Tw + b)) + [y_i = -1]\\log(1 - \\sigma(x^Tw + b)) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each classifier and dataset we tune the regularisation hyperparameter on the validation set and then results are for the test set with best hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvxpysvm import SVM, SVMPrimal, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from hyperopt import fmin, tpe, hp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrvm import RVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(clf, X, y):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    return 1 - (clf.predict(X_val) == y_val).mean()\n",
    "\n",
    "def accuracy(clf, X, y, sparsity=False):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    obj = lambda params: objective(clf(**params), X=X_train, y=y_train)\n",
    "    space = {\"lambd\" : hp.loguniform('lambd', -3, 2.)}\n",
    "    best = fmin(obj, space, algo=tpe.suggest, max_evals=50, rstate=np.random.RandomState(42))\n",
    "    print(\"Best Lambda: \", best[\"lambd\"])\n",
    "    best_clf = clf(best[\"lambd\"])\n",
    "    best_clf.fit(X_train, y_train)\n",
    "    if sparsity:\n",
    "        print(\"Sparsity: \", best_clf.sparsity)\n",
    "    return (best_clf.predict(X_test) == y_test).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=100, n_features=2, n_informative=2, n_redundant=0, random_state=42)\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "accuracy(SVMPrimal, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "accuracy(lambda lambd: LogisticRegression(lambd, norm=2), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "accuracy(lambda lambd: LogisticRegression(lambd, norm=1), X, y, sparsity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "accuracy(lambda lambd: SVM(C=lambd, kernel=\"linear\"), X, y, sparsity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "accuracy(lambda lambd: SVM(C=lambd, kernel=\"poly\"), X, y, sparsity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "accuracy(lambda lambd: SVM(C=lambd, kernel=\"rbf\"), X, y, sparsity=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast cancer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./Breast_cancer_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_radius</th>\n",
       "      <th>mean_texture</th>\n",
       "      <th>mean_perimeter</th>\n",
       "      <th>mean_area</th>\n",
       "      <th>mean_smoothness</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_radius  mean_texture  mean_perimeter  mean_area  mean_smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   diagnosis  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"diagnosis\"].values\n",
    "X = data.drop(\"diagnosis\", axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "accuracy(SVMPrimal, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "accuracy(lambda lambd: LogisticRegression(lambd, norm=2), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "accuracy(lambda lambd: LogisticRegression(lambd, norm=1), X, y, sparsity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "accuracy(lambda lambd: SVM(C=lambd, kernel=\"linear\"), X, y, sparsity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "accuracy(lambda lambd: SVM(C=lambd, kernel=\"poly\"), X, y, sparsity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "accuracy(lambda lambd: SVM(C=lambd, kernel=\"rbf\"), X, y, sparsity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9473684210526315\n",
      "Sparsity:  0.9956043956043956\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "np.random.seed(42)\n",
    "clf = RVC(kernel=\"linear\")\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test))\n",
    "print(\"Sparsity: \", 1 - ((len(clf.m_) - 1) / X_train.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.956140350877193\n",
      "Sparsity:  0.9956043956043956\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "np.random.seed(42)\n",
    "clf = RVC(kernel=\"poly\")\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test))\n",
    "print(\"Sparsity: \", 1 - ((len(clf.m_) - 1) / X_train.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9649122807017544\n",
      "Sparsity:  0.9868131868131869\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "np.random.seed(42)\n",
    "clf = RVC(kernel=\"rbf\")\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test))\n",
    "print(\"Sparsity: \", 1 - ((len(clf.m_) - 1) / X_train.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pima Indians diabetes data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./PimaIndians.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>glucose</th>\n",
       "      <th>diastolic</th>\n",
       "      <th>triceps</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>age</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>70</td>\n",
       "      <td>45</td>\n",
       "      <td>543</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>60</td>\n",
       "      <td>23</td>\n",
       "      <td>846</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.398</td>\n",
       "      <td>59</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnant  glucose  diastolic  triceps  insulin   bmi  diabetes  age  \\\n",
       "0         1       89         66       23       94  28.1     0.167   21   \n",
       "1         0      137         40       35      168  43.1     2.288   33   \n",
       "2         3       78         50       32       88  31.0     0.248   26   \n",
       "3         2      197         70       45      543  30.5     0.158   53   \n",
       "4         1      189         60       23      846  30.1     0.398   59   \n",
       "\n",
       "      test  \n",
       "0  negatif  \n",
       "1  positif  \n",
       "2  positif  \n",
       "3  positif  \n",
       "4  positif  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"test\"].values\n",
    "X = data.drop(\"test\", axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[y == 'negatif'] = 0\n",
    "y[y == 'positif'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "accuracy(SVMPrimal, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "accuracy(lambda lambd: LogisticRegression(lambd, norm=2), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "accuracy(lambda lambd: LogisticRegression(lambd, norm=1), X, y, sparsity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "accuracy(lambda lambd: SVM(C=lambd, kernel=\"linear\"), X, y, sparsity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "accuracy(lambda lambd: SVM(C=lambd, kernel=\"poly\"), X, y, sparsity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "accuracy(lambda lambd: SVM(C=lambd, kernel=\"rbf\"), X, y, sparsity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7721518987341772\n",
      "Sparsity:  0.9904153354632588\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "np.random.seed(42)\n",
    "clf = RVC(kernel=\"linear\")\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test))\n",
    "print(\"Sparsity: \", 1 - ((len(clf.m_) - 1) / X_train.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7341772151898734\n",
      "Sparsity:  0.9456869009584664\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "np.random.seed(42)\n",
    "clf = RVC(kernel=\"poly\")\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test))\n",
    "print(\"Sparsity: \", 1 - ((len(clf.m_) - 1) / X_train.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7341772151898734\n",
      "Sparsity:  0.9584664536741214\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "np.random.seed(42)\n",
    "clf = RVC(kernel=\"rbf\")\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test))\n",
    "print(\"Sparsity: \", 1 - ((len(clf.m_) - 1) / X_train.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Banknote dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"banknote.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.6661</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.1674</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.6383</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.5228</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.4552</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2        3  4\n",
       "0  3.62160  8.6661 -2.8073 -0.44699  0\n",
       "1  4.54590  8.1674 -2.4586 -1.46210  0\n",
       "2  3.86600 -2.6383  1.9242  0.10645  0\n",
       "3  3.45660  9.5228 -4.0112 -3.59440  0\n",
       "4  0.32924 -4.4552  4.5718 -0.98880  0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[4].values\n",
    "X = data.drop(4, axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "accuracy(SVMPrimal, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "accuracy(lambda lambd: LogisticRegression(lambd, norm=2), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "accuracy(lambda lambd: LogisticRegression(lambd, norm=1), X, y, sparsity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "accuracy(lambda lambd: SVM(C=lambd, kernel=\"linear\"), X, y, sparsity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "accuracy(lambda lambd: SVM(C=lambd, kernel=\"poly\"), X, y, sparsity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "accuracy(lambda lambd: SVM(C=lambd, kernel=\"rbf\"), X, y, sparsity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9854545454545455\n",
      "Sparsity:  0.9963536918869644\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "np.random.seed(42)\n",
    "clf = RVC(kernel=\"linear\")\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test))\n",
    "print(\"Sparsity: \", 1 - ((len(clf.m_) - 1) / X_train.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "Sparsity:  0.9945305378304466\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "np.random.seed(42)\n",
    "clf = RVC(kernel=\"poly\")\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test))\n",
    "print(\"Sparsity: \", 1 - ((len(clf.m_) - 1) / X_train.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9927272727272727\n",
      "Sparsity:  0.9981768459434822\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "np.random.seed(42)\n",
    "clf = RVC(kernel=\"rbf\")\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test))\n",
    "print(\"Sparsity: \", 1 - ((len(clf.m_) - 1) / X_train.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ionosphere dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"ionosphere.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[34].values\n",
    "y[y == \"b\"] = 0\n",
    "y[y == \"g\"] = 1\n",
    "X = data.drop(34, axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "accuracy(SVMPrimal, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "accuracy(lambda lambd: LogisticRegression(lambd, norm=2), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "accuracy(lambda lambd: LogisticRegression(lambd, norm=1), X, y, sparsity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "accuracy(lambda lambd: SVM(C=lambd, kernel=\"linear\"), X, y, sparsity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "accuracy(lambda lambd: SVM(C=lambd, kernel=\"rbf\"), X, y, sparsity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "accuracy(lambda lambd: SVM(C=lambd, kernel=\"poly\"), X, y, sparsity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8732394366197183\n",
      "Sparsity:  0.9678571428571429\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "np.random.seed(42)\n",
    "clf = RVC(kernel=\"linear\")\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test))\n",
    "print(\"Sparsity: \", 1 - ((len(clf.m_) - 1) / X_train.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/agadetsky/.pyenv/versions/3.6.6/lib/python3.6/site-packages/skrvm/rvm.py:239: RuntimeWarning: divide by zero encountered in log\n",
      "  np.sum(np.log(1-y[t == 0]), 0))\n",
      "/Users/agadetsky/.pyenv/versions/3.6.6/lib/python3.6/site-packages/skrvm/rvm.py:239: RuntimeWarning: divide by zero encountered in log\n",
      "  np.sum(np.log(1-y[t == 0]), 0))\n",
      "/Users/agadetsky/.pyenv/versions/3.6.6/lib/python3.6/site-packages/skrvm/rvm.py:239: RuntimeWarning: divide by zero encountered in log\n",
      "  np.sum(np.log(1-y[t == 0]), 0))\n",
      "/Users/agadetsky/.pyenv/versions/3.6.6/lib/python3.6/site-packages/skrvm/rvm.py:239: RuntimeWarning: divide by zero encountered in log\n",
      "  np.sum(np.log(1-y[t == 0]), 0))\n",
      "/Users/agadetsky/.pyenv/versions/3.6.6/lib/python3.6/site-packages/skrvm/rvm.py:239: RuntimeWarning: divide by zero encountered in log\n",
      "  np.sum(np.log(1-y[t == 0]), 0))\n",
      "/Users/agadetsky/.pyenv/versions/3.6.6/lib/python3.6/site-packages/skrvm/rvm.py:239: RuntimeWarning: divide by zero encountered in log\n",
      "  np.sum(np.log(1-y[t == 0]), 0))\n",
      "/Users/agadetsky/.pyenv/versions/3.6.6/lib/python3.6/site-packages/skrvm/rvm.py:239: RuntimeWarning: divide by zero encountered in log\n",
      "  np.sum(np.log(1-y[t == 0]), 0))\n",
      "/Users/agadetsky/.pyenv/versions/3.6.6/lib/python3.6/site-packages/skrvm/rvm.py:239: RuntimeWarning: divide by zero encountered in log\n",
      "  np.sum(np.log(1-y[t == 0]), 0))\n",
      "/Users/agadetsky/.pyenv/versions/3.6.6/lib/python3.6/site-packages/skrvm/rvm.py:239: RuntimeWarning: divide by zero encountered in log\n",
      "  np.sum(np.log(1-y[t == 0]), 0))\n",
      "/Users/agadetsky/.pyenv/versions/3.6.6/lib/python3.6/site-packages/skrvm/rvm.py:239: RuntimeWarning: divide by zero encountered in log\n",
      "  np.sum(np.log(1-y[t == 0]), 0))\n",
      "/Users/agadetsky/.pyenv/versions/3.6.6/lib/python3.6/site-packages/skrvm/rvm.py:239: RuntimeWarning: divide by zero encountered in log\n",
      "  np.sum(np.log(1-y[t == 0]), 0))\n",
      "/Users/agadetsky/.pyenv/versions/3.6.6/lib/python3.6/site-packages/skrvm/rvm.py:239: RuntimeWarning: divide by zero encountered in log\n",
      "  np.sum(np.log(1-y[t == 0]), 0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8732394366197183\n",
      "Sparsity:  0.9535714285714285\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "np.random.seed(42)\n",
    "clf = RVC(kernel=\"poly\")\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test))\n",
    "print(\"Sparsity: \", 1 - ((len(clf.m_) - 1) / X_train.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.971830985915493\n",
      "Sparsity:  0.9607142857142857\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "np.random.seed(42)\n",
    "clf = RVC(kernel=\"rbf\")\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test))\n",
    "print(\"Sparsity: \", 1 - ((len(clf.m_) - 1) / X_train.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"wine.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1     2     3     4    5     6     7     8     9     10    11    12  \\\n",
       "0   1  14.23  1.71  2.43  15.6  127  2.80  3.06  0.28  2.29  5.64  1.04  3.92   \n",
       "1   1  13.20  1.78  2.14  11.2  100  2.65  2.76  0.26  1.28  4.38  1.05  3.40   \n",
       "2   1  13.16  2.36  2.67  18.6  101  2.80  3.24  0.30  2.81  5.68  1.03  3.17   \n",
       "3   1  14.37  1.95  2.50  16.8  113  3.85  3.49  0.24  2.18  7.80  0.86  3.45   \n",
       "4   1  13.24  2.59  2.87  21.0  118  2.80  2.69  0.39  1.82  4.32  1.04  2.93   \n",
       "\n",
       "     13  \n",
       "0  1065  \n",
       "1  1050  \n",
       "2  1185  \n",
       "3  1480  \n",
       "4   735  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[0].values\n",
    "y[y <= 1] = 0\n",
    "y[y > 1] = 1\n",
    "X = data.drop(0, axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "accuracy(SVMPrimal, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "accuracy(lambda lambd: LogisticRegression(lambd, norm=2), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "accuracy(lambda lambd: LogisticRegression(lambd, norm=1), X, y, sparsity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "accuracy(lambda lambd: SVM(C=lambd, kernel=\"linear\"), X, y, sparsity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "accuracy(lambda lambd: SVM(C=lambd, kernel=\"poly\"), X, y, sparsity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "accuracy(lambda lambd: SVM(C=lambd, kernel=\"rbf\"), X, y, sparsity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "Sparsity:  0.971830985915493\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "np.random.seed(42)\n",
    "clf = RVC(kernel=\"linear\")\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test))\n",
    "print(\"Sparsity: \", 1 - ((len(clf.m_) - 1) / X_train.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "Sparsity:  0.971830985915493\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "np.random.seed(42)\n",
    "clf = RVC(kernel=\"linear\")\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test))\n",
    "print(\"Sparsity: \", 1 - ((len(clf.m_) - 1) / X_train.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "Sparsity:  0.971830985915493\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "np.random.seed(42)\n",
    "clf = RVC(kernel=\"linear\")\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test))\n",
    "print(\"Sparsity: \", 1 - ((len(clf.m_) - 1) / X_train.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM: MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.datasets import fetch_mldata\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_mldata('MNIST original', data_home='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = mnist.data\n",
    "targets = mnist.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_0 = images[targets == 1]\n",
    "X_1 = images[targets == 8]\n",
    "y_0 = targets[targets == 1]\n",
    "y_1 = targets[targets == 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "_X = np.vstack([X_0, X_1])\n",
    "y = np.hstack([y_0, y_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "shuffle_idx = np.arange(X.shape[0])\n",
    "np.random.shuffle(shuffle_idx)\n",
    "_X = _X[shuffle_idx]\n",
    "y = y[shuffle_idx]\n",
    "X = StandardScaler().fit_transform(_X.astype(np.float64) / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X[:2000], y[:2000], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVM(C=.1, kernel=\"linear\")\n",
    "\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "np.mean(clf.predict(X_test) == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity rate 0.838\n"
     ]
    }
   ],
   "source": [
    "print('sparsity rate {:.3f}'.format(clf.sparsity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.title(r'$\\lambda = ${:.5f}'.format(clf.lambd[order[i]]))\n",
    "    plt.imshow(_X[order[i]].reshape((28, 28)), cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.savefig('mnist.png', dpi=300, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
